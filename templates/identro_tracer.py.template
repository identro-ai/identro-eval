# ===== IDENTRO TRACER - Shared Module =====
# Generated by Identro - Do not edit manually
# This tracer captures execution traces during CrewAI test runs
# and writes them to .identro/traces/ for visualization in the dashboard.

import json
import time
import functools
import os
import atexit
import contextvars
import re
from typing import Optional, Dict, Any, List

# Async-safe current span tracking
_current_span: contextvars.ContextVar[Optional[Dict]] = contextvars.ContextVar('current_span', default=None)

# Re-entrancy guard for flow kickoff to prevent nested spans
_in_flow_kickoff: contextvars.ContextVar[bool] = contextvars.ContextVar('in_flow_kickoff', default=False)

class IdentroTracer:
    """Local-first observability tracer for CrewAI execution traces."""
    __slots__ = ('trace_dir', 'run_id', 'test_id', 'run_index', 'agent_name', 'spans', 'enabled', '_flushed', '_file_initialized')
    
    def __init__(self):
        self.trace_dir = ".identro/traces"
        self.run_id = os.environ.get('IDENTRO_RUN_ID', str(int(time.time() * 1000)))
        # Test context from environment for multi-run support
        self.test_id = os.environ.get('IDENTRO_TEST_ID', '')
        self.run_index = os.environ.get('IDENTRO_RUN_INDEX', '-1')
        self.agent_name = os.environ.get('IDENTRO_AGENT_NAME', '')
        self.spans: List[Dict] = []
        self.enabled = os.environ.get('IDENTRO_TRACING', '1') == '1'
        self._flushed = False
        self._file_initialized = set()  # Track which files have been initialized (truncated)
        
        if self.enabled:
            os.makedirs(self.trace_dir, exist_ok=True)
    
    def _get_trace_file(self) -> str:
        """Get trace file path based on test context."""
        if self.test_id:
            # test_id may already include -runN suffix from TypeScript
            # Don't add run_index if it's already in the test_id
            if re.search(r'-run\d+$', self.test_id):
                # test_id already has run suffix, use as-is
                return f"{self.trace_dir}/trace-{self.test_id}.jsonl"
            elif self.run_index != '-1':
                # Multi-run: separate file per test+run
                return f"{self.trace_dir}/trace-{self.test_id}-run{self.run_index}.jsonl"
            else:
                # Single run: file per test
                return f"{self.trace_dir}/trace-{self.test_id}.jsonl"
        else:
            # No context: default file
            return f"{self.trace_dir}/traces.jsonl"
    
    def set_context(self, test_id: str = '', run_index: str = '-1', agent_name: str = ''):
        """Update tracer context for a new test."""
        self.test_id = test_id
        self.run_index = run_index
        self.agent_name = agent_name
        self._flushed = False
    
    def start_span(self, span_type: str, data: Dict) -> Optional[Dict]:
        """Start a new span and set it as the current context."""
        if not self.enabled:
            return None
            
        parent = _current_span.get()
        span = {
            "id": f"{span_type}_{len(self.spans)}_{self.run_id}",
            "parent_id": parent["id"] if parent else None,
            "type": span_type,
            "start_time": time.time() * 1000,
            "data": {k: str(v)[:500] if isinstance(v, str) else v for k, v in data.items()},
            "test_context": {
                "test_id": self.test_id,
                "run_index": self.run_index,
                "agent_name": self.agent_name
            }
        }
        self.spans.append(span)
        _current_span.set(span)
        return span
    
    def end_span(self, span: Optional[Dict], result: Any = None, error: Exception = None) -> None:
        """End a span and restore the parent context."""
        if not span or not self.enabled:
            return
            
        span["end_time"] = time.time() * 1000
        span["duration_ms"] = span["end_time"] - span["start_time"]
        
        if result is not None:
            result_str = str(result)
            span["data"]["result"] = result_str[:500] if len(result_str) > 500 else result_str
        if error is not None:
            span["error"] = str(error)[:500]
        
        # Restore parent context
        parent_id = span.get("parent_id")
        if parent_id:
            parent = next((s for s in self.spans if s["id"] == parent_id), None)
            _current_span.set(parent)
        else:
            _current_span.set(None)
    
    # ===== Flow-specific span helpers =====
    
    def start_span_with_state(self, span_type: str, data: Dict, state_before: Dict = None) -> Optional[Dict]:
        """Start span with state capture for diff tracking."""
        span = self.start_span(span_type, data)
        if span and state_before is not None:
            span["state_before"] = self._serialize_state(state_before)
        return span
    
    def end_span_with_state(self, span: Optional[Dict], result: Any = None, 
                            error: Exception = None, state_after: Dict = None) -> None:
        """End span with state diff calculation."""
        if span and state_after is not None:
            span["state_after"] = self._serialize_state(state_after)
            if "state_before" in span:
                span["state_diff"] = self._calculate_diff(span["state_before"], span["state_after"])
        self.end_span(span, result, error)
    
    def _serialize_state(self, state: Any) -> Dict:
        """Serialize state for storage (handle Pydantic, dataclass, etc.)."""
        if hasattr(state, 'model_dump'):
            return state.model_dump()
        elif hasattr(state, '__dataclass_fields__'):
            from dataclasses import asdict
            return asdict(state)
        elif hasattr(state, '__dict__'):
            return {k: v for k, v in state.__dict__.items() if not k.startswith('_')}
        elif isinstance(state, dict):
            return state
        return {'raw': str(state)[:500]}
    
    def _calculate_diff(self, before: Dict, after: Dict) -> Dict:
        """Calculate state diff - only changed fields."""
        diff = {}
        all_keys = set(before.keys()) | set(after.keys())
        for key in all_keys:
            before_val = before.get(key)
            after_val = after.get(key)
            if before_val != after_val:
                diff[key] = {'before': before_val, 'after': after_val}
        return diff
    
    def record_hitl_interaction(self, method: str, prompt: str, response: Any, 
                                 is_synthetic: bool = True) -> Optional[Dict]:
        """Record HITL interaction as a span."""
        span = self.start_span("hitl_interaction", {
            "method": method,
            "prompt": str(prompt)[:500],
            "response": str(response)[:500],
            "is_synthetic": is_synthetic,
            "synthetic_source": "flow-test-generator" if is_synthetic else "user"
        })
        self.end_span(span)
        return span
    
    def record_routing_decision(self, router_method: str, condition: str, 
                                 selected: str, available: List[str]) -> Optional[Dict]:
        """Record routing decision as a span."""
        span = self.start_span("routing_decision", {
            "router_method": router_method,
            "condition": str(condition)[:300],
            "selected_path": selected,
            "available_paths": available
        })
        self.end_span(span)
        return span
    
    def flush(self) -> None:
        """Write all spans to file at end of execution (lazy write).
        
        IMPORTANT: First write to a file truncates it (mode 'w') to prevent
        accumulation of traces from previous sessions. Subsequent writes
        append (mode 'a').
        """
        if not self.enabled or not self.spans or self._flushed:
            return
            
        self._flushed = True
        try:
            trace_file = self._get_trace_file()
            # Use 'w' mode for first write to this file (truncates old data)
            # Use 'a' mode for subsequent writes within the same session
            mode = 'w' if trace_file not in self._file_initialized else 'a'
            with open(trace_file, mode) as f:
                for span in self.spans:
                    f.write(json.dumps(span) + "\n")
            self._file_initialized.add(trace_file)
        except Exception as e:
            # Silently fail - never break user code
            pass

    def reset(self):
        """Reset spans for next test."""
        self.spans = []
        self._flushed = False

# Global tracer instance
_identro_tracer = IdentroTracer()

# Register flush on exit
atexit.register(_identro_tracer.flush)

def _patch_openai_sdk() -> None:
    """Patch OpenAI SDK BEFORE CrewAI imports it. CrewAI 1.6+ uses OpenAI directly."""
    try:
        from openai.resources.chat import completions
        
        # Patch SYNC Completions.create
        if hasattr(completions, 'Completions') and hasattr(completions.Completions, 'create'):
            if not getattr(completions.Completions.create, '_identro_patched', False):
                original_create = completions.Completions.create
                @functools.wraps(original_create)
                def traced_create(self, *args, **kwargs):
                    model = kwargs.get('model', 'unknown')
                    messages = kwargs.get('messages', [])
                    
                    # Truncate messages for storage
                    messages_str = str(messages)[:500] if messages else ''
                    
                    span = _identro_tracer.start_span("llm_call", {
                        "model": str(model),
                        "provider": "openai",
                        "sync": True,
                        "prompt": messages_str
                    })
                    try:
                        result = original_create(self, *args, **kwargs)
                        response_content = ""
                        tokens = {}
                        if hasattr(result, 'choices') and result.choices:
                            choice = result.choices[0]
                            if hasattr(choice, 'message') and hasattr(choice.message, 'content'):
                                response_content = str(choice.message.content)[:500]
                        if hasattr(result, 'usage') and result.usage:
                            tokens = {
                                "prompt": getattr(result.usage, 'prompt_tokens', 0),
                                "completion": getattr(result.usage, 'completion_tokens', 0),
                                "total": getattr(result.usage, 'total_tokens', 0)
                            }
                        if span:
                            span["data"]["response"] = response_content
                            span["data"]["tokens"] = tokens
                        _identro_tracer.end_span(span, result="success")
                        return result
                    except Exception as e:
                        _identro_tracer.end_span(span, error=e)
                        raise
                traced_create._identro_patched = True
                completions.Completions.create = traced_create
        
        # Patch ASYNC AsyncCompletions.create
        if hasattr(completions, 'AsyncCompletions') and hasattr(completions.AsyncCompletions, 'create'):
            if not getattr(completions.AsyncCompletions.create, '_identro_patched', False):
                original_async_create = completions.AsyncCompletions.create
                
                async def traced_async_create(self, *args, **kwargs):
                    model = kwargs.get('model', 'unknown')
                    messages = kwargs.get('messages', [])
                    
                    messages_str = str(messages)[:500] if messages else ''
                    
                    span = _identro_tracer.start_span("llm_call", {
                        "model": str(model),
                        "provider": "openai",
                        "async": True,
                        "prompt": messages_str
                    })
                    try:
                        result = await original_async_create(self, *args, **kwargs)
                        response_content = ""
                        tokens = {}
                        if hasattr(result, 'choices') and result.choices:
                            choice = result.choices[0]
                            if hasattr(choice, 'message') and hasattr(choice.message, 'content'):
                                response_content = str(choice.message.content)[:500]
                        if hasattr(result, 'usage') and result.usage:
                            tokens = {
                                "prompt": getattr(result.usage, 'prompt_tokens', 0),
                                "completion": getattr(result.usage, 'completion_tokens', 0),
                                "total": getattr(result.usage, 'total_tokens', 0)
                            }
                        if span:
                            span["data"]["response"] = response_content
                            span["data"]["tokens"] = tokens
                        _identro_tracer.end_span(span, result="success")
                        return result
                    except Exception as e:
                        _identro_tracer.end_span(span, error=e)
                        raise
                traced_async_create._identro_patched = True
                completions.AsyncCompletions.create = traced_async_create
                
    except ImportError:
        pass  # openai not available

def _patch_crewai_llm() -> None:
    """Patch CrewAI's internal LLM class. Call AFTER importing CrewAI."""
    try:
        from crewai.llm import LLM as CrewAILLM
        
        # Patch the call method (sync LLM calls)
        if hasattr(CrewAILLM, 'call') and not getattr(CrewAILLM.call, '_identro_patched', False):
            original_call = CrewAILLM.call
            @functools.wraps(original_call)
            def traced_llm_call(self, messages, *args, **kwargs):
                model = getattr(self, 'model', 'unknown')
                messages_str = str(messages)[:500] if messages else ''
                
                span = _identro_tracer.start_span("llm_call", {
                    "model": str(model),
                    "provider": "crewai.LLM",
                    "prompt": messages_str
                })
                try:
                    result = original_call(self, messages, *args, **kwargs)
                    response_str = str(result)[:500] if result else ''
                    span["data"]["response"] = response_str
                    _identro_tracer.end_span(span, result="success")
                    return result
                except Exception as e:
                    _identro_tracer.end_span(span, error=e)
                    raise
            traced_llm_call._identro_patched = True
            CrewAILLM.call = traced_llm_call
            
    except ImportError:
        pass  # CrewAI LLM class not available (older version)

def _clean_agent_name(role: str) -> str:
    """Extract clean agent name from role."""
    if not role:
        return 'unknown'
    
    role = role.strip().replace('\n', ' ').strip()
    clean = role.replace('{topic}', '').replace('{task}', '').replace('{input}', '').strip()
    
    if len(clean) <= 50:
        return clean
    
    role_keywords = ['Analyst', 'Agent', 'Expert', 'Manager', 'Writer', 'Researcher', 'Coordinator', 'Specialist']
    for keyword in role_keywords:
        if keyword in clean:
            parts = clean.split()
            for i, part in enumerate(parts):
                if keyword in part:
                    title_parts = []
                    start = max(0, i - 3)
                    for j in range(start, i + 1):
                        word = parts[j]
                        if word and len(word) <= 20 and (word[0].isupper() or word in ['and', 'of', 'the']):
                            title_parts.append(word)
                        elif j == i:
                            title_parts.append(word)
                    if title_parts:
                        return ' '.join(title_parts)
    
    return clean[-50:] if len(clean) > 50 else clean

def instrument_crewai() -> None:
    """Instrument CrewAI classes for observability. Call AFTER importing CrewAI."""
    try:
        _instrument_p0()  # Crew, Task, Flow
        _instrument_p1()  # Agent, LiteLLM
        _instrument_p2()  # Tools
    except Exception as e:
        # Never break user code - silently disable tracing
        _identro_tracer.enabled = False

def _instrument_p0() -> None:
    """P0: Patch critical entry points - Crew.kickoff (sync+async), Task.execute, Flow.kickoff"""
    from crewai import Crew, Task
    
    # Helper to extract crew metadata
    def _get_crew_span_data(crew_instance, inputs=None):
        resolved_agents = []
        for a in getattr(crew_instance, 'agents', [])[:10]:
            role = getattr(a, 'role', str(a))
            clean_name = _clean_agent_name(role)
            resolved_agents.append(clean_name)
        
        return {
            "crew_name": crew_instance.__class__.__name__,
            "agents": resolved_agents,
            "tasks": len(getattr(crew_instance, 'tasks', [])),
            "process": str(getattr(crew_instance, 'process', 'unknown')),
            "inputs": str(inputs)[:300] if inputs else ""
        }
    
    # Crew.kickoff (sync)
    if hasattr(Crew, 'kickoff') and not getattr(Crew.kickoff, '_identro_patched', False):
        original_crew_kickoff = Crew.kickoff
        @functools.wraps(original_crew_kickoff)
        def traced_crew_kickoff(self, *args, **kwargs):
            inputs = kwargs.get('inputs', {}) or {}
            span = _identro_tracer.start_span("crew_kickoff", _get_crew_span_data(self, inputs))
            try:
                result = original_crew_kickoff(self, *args, **kwargs)
                _identro_tracer.end_span(span, result=result)
                return result
            except Exception as e:
                _identro_tracer.end_span(span, error=e)
                raise
        traced_crew_kickoff._identro_patched = True
        Crew.kickoff = traced_crew_kickoff
    
    # Crew.kickoff_async (async - used by flows internally)
    if hasattr(Crew, 'kickoff_async') and not getattr(Crew.kickoff_async, '_identro_patched', False):
        original_crew_kickoff_async = Crew.kickoff_async
        
        async def traced_crew_kickoff_async(self, *args, **kwargs):
            inputs = kwargs.get('inputs', {}) or {}
            span = _identro_tracer.start_span("crew_kickoff", _get_crew_span_data(self, inputs))
            try:
                result = await original_crew_kickoff_async(self, *args, **kwargs)
                _identro_tracer.end_span(span, result=result)
                return result
            except Exception as e:
                _identro_tracer.end_span(span, error=e)
                raise
        traced_crew_kickoff_async._identro_patched = True
        Crew.kickoff_async = traced_crew_kickoff_async
    
    # Crew.kickoff_for_each (sync batch)
    if hasattr(Crew, 'kickoff_for_each') and not getattr(Crew.kickoff_for_each, '_identro_patched', False):
        original_kickoff_for_each = Crew.kickoff_for_each
        @functools.wraps(original_kickoff_for_each)
        def traced_kickoff_for_each(self, inputs, *args, **kwargs):
            span = _identro_tracer.start_span("crew_kickoff_batch", {
                **_get_crew_span_data(self, None),
                "batch_size": len(inputs) if isinstance(inputs, list) else 1,
                "batch_type": "for_each"
            })
            try:
                result = original_kickoff_for_each(self, inputs, *args, **kwargs)
                _identro_tracer.end_span(span, result="batch_complete")
                return result
            except Exception as e:
                _identro_tracer.end_span(span, error=e)
                raise
        traced_kickoff_for_each._identro_patched = True
        Crew.kickoff_for_each = traced_kickoff_for_each
    
    # Crew.kickoff_for_each_async (async batch - used by flows)
    if hasattr(Crew, 'kickoff_for_each_async') and not getattr(Crew.kickoff_for_each_async, '_identro_patched', False):
        original_kickoff_for_each_async = Crew.kickoff_for_each_async
        
        async def traced_kickoff_for_each_async(self, inputs, *args, **kwargs):
            span = _identro_tracer.start_span("crew_kickoff_batch", {
                **_get_crew_span_data(self, None),
                "batch_size": len(inputs) if isinstance(inputs, list) else 1,
                "batch_type": "for_each_async"
            })
            try:
                result = await original_kickoff_for_each_async(self, inputs, *args, **kwargs)
                _identro_tracer.end_span(span, result="batch_complete")
                return result
            except Exception as e:
                _identro_tracer.end_span(span, error=e)
                raise
        traced_kickoff_for_each_async._identro_patched = True
        Crew.kickoff_for_each_async = traced_kickoff_for_each_async
    
    # Task.execute
    if hasattr(Task, 'execute') and not getattr(Task.execute, '_identro_patched', False):
        original_task_execute = Task.execute
        @functools.wraps(original_task_execute)
        def traced_task_execute(self, *args, **kwargs):
            span = _identro_tracer.start_span("task_execute", {
                "task_description": str(getattr(self, 'description', ''))[:300],
                "agent_role": getattr(getattr(self, 'agent', None), 'role', 'unknown')
            })
            try:
                result = original_task_execute(self, *args, **kwargs)
                _identro_tracer.end_span(span, result=result)
                return result
            except Exception as e:
                _identro_tracer.end_span(span, error=e)
                raise
        traced_task_execute._identro_patched = True
        Task.execute = traced_task_execute
    
    # Task.execute_async (async - used internally)
    if hasattr(Task, 'execute_async') and not getattr(Task.execute_async, '_identro_patched', False):
        original_task_execute_async = Task.execute_async
        
        async def traced_task_execute_async(self, *args, **kwargs):
            span = _identro_tracer.start_span("task_execute", {
                "task_description": str(getattr(self, 'description', ''))[:300],
                "agent_role": getattr(getattr(self, 'agent', None), 'role', 'unknown')
            })
            try:
                result = await original_task_execute_async(self, *args, **kwargs)
                _identro_tracer.end_span(span, result=result)
                return result
            except Exception as e:
                _identro_tracer.end_span(span, error=e)
                raise
        traced_task_execute_async._identro_patched = True
        Task.execute_async = traced_task_execute_async
    
    # Flow.kickoff (sync) - with re-entrancy guard to prevent nested spans
    try:
        from crewai.flow.flow import Flow
        if hasattr(Flow, 'kickoff') and not getattr(Flow.kickoff, '_identro_patched', False):
            original_flow_kickoff = Flow.kickoff
            @functools.wraps(original_flow_kickoff)
            def traced_flow_kickoff(self, *args, **kwargs):
                # Re-entrancy guard: skip if already tracing a flow kickoff
                if _in_flow_kickoff.get():
                    return original_flow_kickoff(self, *args, **kwargs)
                
                # Set guard and create span
                token = _in_flow_kickoff.set(True)
                try:
                    initial_state = {}
                    if hasattr(self, 'state'):
                        try:
                            if hasattr(self.state, 'model_dump'):
                                initial_state = self.state.model_dump()
                            elif hasattr(self.state, '__dict__'):
                                initial_state = {k: v for k, v in self.state.__dict__.items() if not k.startswith('_')}
                        except:
                            initial_state = str(getattr(self, 'state', {}))[:300]
                    
                    span = _identro_tracer.start_span_with_state("flow_kickoff", {
                        "flow_name": self.__class__.__name__,
                        "initial_state": str(initial_state)[:500]
                    }, initial_state)
                    try:
                        result = original_flow_kickoff(self, *args, **kwargs)
                        
                        # Capture final state
                        final_state = {}
                        if hasattr(self, 'state'):
                            try:
                                if hasattr(self.state, 'model_dump'):
                                    final_state = self.state.model_dump()
                                elif hasattr(self.state, '__dict__'):
                                    final_state = {k: v for k, v in self.state.__dict__.items() if not k.startswith('_')}
                            except:
                                final_state = str(getattr(self, 'state', {}))[:300]
                        
                        _identro_tracer.end_span_with_state(span, result=result, state_after=final_state)
                        return result
                    except Exception as e:
                        _identro_tracer.end_span(span, error=e)
                        raise
                finally:
                    _in_flow_kickoff.reset(token)
            traced_flow_kickoff._identro_patched = True
            Flow.kickoff = traced_flow_kickoff
        
        # Flow.kickoff_async (async) - with re-entrancy guard
        if hasattr(Flow, 'kickoff_async') and not getattr(Flow.kickoff_async, '_identro_patched', False):
            original_flow_kickoff_async = Flow.kickoff_async
            
            async def traced_flow_kickoff_async(self, *args, **kwargs):
                # Re-entrancy guard: skip if already tracing a flow kickoff
                if _in_flow_kickoff.get():
                    return await original_flow_kickoff_async(self, *args, **kwargs)
                
                # Set guard and create span
                token = _in_flow_kickoff.set(True)
                try:
                    initial_state = {}
                    if hasattr(self, 'state'):
                        try:
                            if hasattr(self.state, 'model_dump'):
                                initial_state = self.state.model_dump()
                            elif hasattr(self.state, '__dict__'):
                                initial_state = {k: v for k, v in self.state.__dict__.items() if not k.startswith('_')}
                        except:
                            initial_state = str(getattr(self, 'state', {}))[:300]
                    
                    span = _identro_tracer.start_span_with_state("flow_kickoff", {
                        "flow_name": self.__class__.__name__,
                        "initial_state": str(initial_state)[:500]
                    }, initial_state)
                    try:
                        result = await original_flow_kickoff_async(self, *args, **kwargs)
                        
                        final_state = {}
                        if hasattr(self, 'state'):
                            try:
                                if hasattr(self.state, 'model_dump'):
                                    final_state = self.state.model_dump()
                                elif hasattr(self.state, '__dict__'):
                                    final_state = {k: v for k, v in self.state.__dict__.items() if not k.startswith('_')}
                            except:
                                final_state = str(getattr(self, 'state', {}))[:300]
                        
                        _identro_tracer.end_span_with_state(span, result=result, state_after=final_state)
                        return result
                    except Exception as e:
                        _identro_tracer.end_span(span, error=e)
                        raise
                finally:
                    _in_flow_kickoff.reset(token)
            traced_flow_kickoff_async._identro_patched = True
            Flow.kickoff_async = traced_flow_kickoff_async
    except ImportError:
        pass

def _instrument_p1() -> None:
    """P1: Patch Agent execution and LLM calls"""
    from crewai import Agent
    
    # Agent execute_task
    for method_name in ['execute_task', '_execute_task']:
        if hasattr(Agent, method_name):
            original_method = getattr(Agent, method_name)
            if getattr(original_method, '_identro_patched', False):
                continue
                
            @functools.wraps(original_method)
            def traced_agent_execute(self, task=None, *args, _original=original_method, **kwargs):
                task_desc = ''
                if task:
                    task_desc = str(getattr(task, 'description', str(task)))[:300]
                agent_role = getattr(self, 'role', 'unknown')
                clean_agent = _clean_agent_name(agent_role)
                span = _identro_tracer.start_span("agent_execute", {
                    "agent": clean_agent,
                    "task": task_desc
                })
                try:
                    if task is not None:
                        result = _original(self, task, *args, **kwargs)
                    else:
                        result = _original(self, *args, **kwargs)
                    _identro_tracer.end_span(span, result=result)
                    return result
                except Exception as e:
                    _identro_tracer.end_span(span, error=e)
                    raise
            traced_agent_execute._identro_patched = True
            setattr(Agent, method_name, traced_agent_execute)
            break
    
    # LiteLLM patching
    try:
        import litellm
        
        if hasattr(litellm, 'completion') and not getattr(litellm.completion, '_identro_patched', False):
            original_completion = litellm.completion
            @functools.wraps(original_completion)
            def traced_completion(*args, **kwargs):
                model = kwargs.get('model', args[0] if args else 'unknown')
                messages = kwargs.get('messages', [])
                messages_str = str(messages)[:500] if messages else ''
                
                span = _identro_tracer.start_span("llm_call", {
                    "model": str(model),
                    "provider": "litellm",
                    "sync": True,
                    "prompt": messages_str
                })
                try:
                    result = original_completion(*args, **kwargs)
                    response_content = ""
                    tokens = {}
                    if hasattr(result, 'choices') and result.choices:
                        response_content = str(getattr(result.choices[0].message, 'content', ''))[:500]
                    if hasattr(result, 'usage') and result.usage:
                        tokens = {
                            "prompt": getattr(result.usage, 'prompt_tokens', 0),
                            "completion": getattr(result.usage, 'completion_tokens', 0)
                        }
                    span["data"]["response"] = response_content
                    span["data"]["tokens"] = tokens
                    _identro_tracer.end_span(span, result="success")
                    return result
                except Exception as e:
                    _identro_tracer.end_span(span, error=e)
                    raise
            traced_completion._identro_patched = True
            litellm.completion = traced_completion
        
        if hasattr(litellm, 'acompletion') and not getattr(litellm.acompletion, '_identro_patched', False):
            original_acompletion = litellm.acompletion
            
            async def traced_acompletion(*args, **kwargs):
                model = kwargs.get('model', args[0] if args else 'unknown')
                messages = kwargs.get('messages', [])
                messages_str = str(messages)[:500] if messages else ''
                
                span = _identro_tracer.start_span("llm_call", {
                    "model": str(model),
                    "provider": "litellm",
                    "async": True,
                    "prompt": messages_str
                })
                try:
                    result = await original_acompletion(*args, **kwargs)
                    response_content = ""
                    tokens = {}
                    if hasattr(result, 'choices') and result.choices:
                        response_content = str(getattr(result.choices[0].message, 'content', ''))[:500]
                    if hasattr(result, 'usage') and result.usage:
                        tokens = {
                            "prompt": getattr(result.usage, 'prompt_tokens', 0),
                            "completion": getattr(result.usage, 'completion_tokens', 0)
                        }
                    span["data"]["response"] = response_content
                    span["data"]["tokens"] = tokens
                    _identro_tracer.end_span(span, result="success")
                    return result
                except Exception as e:
                    _identro_tracer.end_span(span, error=e)
                    raise
            traced_acompletion._identro_patched = True
            litellm.acompletion = traced_acompletion
            
    except ImportError:
        pass

def _instrument_p2() -> None:
    """P2: Patch tool execution"""
    try:
        from crewai.tools.structured_tool import CrewStructuredTool
        
        if hasattr(CrewStructuredTool, 'invoke') and not getattr(CrewStructuredTool.invoke, '_identro_patched', False):
            original_invoke = CrewStructuredTool.invoke
            @functools.wraps(original_invoke)
            def traced_structured_tool_invoke(self, input, config=None, **kwargs):
                tool_name = getattr(self, 'name', self.__class__.__name__)
                tool_input = ''
                try:
                    if isinstance(input, dict):
                        tool_input = str(input)[:300]
                    else:
                        tool_input = str(input)[:300]
                except:
                    pass
                
                span = _identro_tracer.start_span("tool_call", {
                    "tool_name": tool_name,
                    "tool_type": "crewai_structured_tool",
                    "tool_input": tool_input
                })
                try:
                    result = original_invoke(self, input, config, **kwargs)
                    _identro_tracer.end_span(span, result=result)
                    return result
                except Exception as e:
                    _identro_tracer.end_span(span, error=e)
                    raise
            traced_structured_tool_invoke._identro_patched = True
            CrewStructuredTool.invoke = traced_structured_tool_invoke
    except ImportError:
        pass
    
    try:
        from crewai.tools.base_tool import BaseTool as CrewAIBaseTool
        
        if hasattr(CrewAIBaseTool, 'run') and not getattr(CrewAIBaseTool.run, '_identro_patched', False):
            original_run = CrewAIBaseTool.run
            @functools.wraps(original_run)
            def traced_crewai_tool_run(self, *args, **kwargs):
                tool_name = getattr(self, 'name', self.__class__.__name__)
                tool_input = ''
                try:
                    if args:
                        tool_input = str(args[0])[:300]
                    elif kwargs:
                        tool_input = str(kwargs)[:300]
                except:
                    pass
                
                span = _identro_tracer.start_span("tool_call", {
                    "tool_name": tool_name,
                    "tool_type": "crewai_base_tool",
                    "tool_input": tool_input
                })
                try:
                    result = original_run(self, *args, **kwargs)
                    _identro_tracer.end_span(span, result=result)
                    return result
                except Exception as e:
                    _identro_tracer.end_span(span, error=e)
                    raise
            traced_crewai_tool_run._identro_patched = True
            CrewAIBaseTool.run = traced_crewai_tool_run
    except ImportError:
        pass
