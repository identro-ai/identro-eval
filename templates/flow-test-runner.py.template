#!/usr/bin/env python3
"""
Identro Flow Test Runner Template
=================================

This template executes a CrewAI Flow with:
- Pre-loaded synthetic HITL responses (no waiting for stdin)
- State capture at each step
- Path validation (verifies expected path is taken)
- Trace building for FlowTrace format

Template variables (replaced at runtime):
- {{PROJECT_PATH}} - Absolute path to the project
- {{FLOW_MODULE}} - Module containing the flow (e.g., 'main')
- {{FLOW_CLASS}} - Flow class name (e.g., 'LeadScoreFlow')
- {{FLOW_INPUTS}} - JSON string of flow.kickoff() inputs
- {{HITL_RESPONSES}} - JSON array of pre-generated HITL responses
- {{EXPECTED_END_STEP}} - Method where path should terminate
- {{TEST_ID}} - Unique test identifier
- {{PATH_ID}} - Target path identifier
- {{ARTIFACT_DIR}} - Directory for capturing artifacts
- {{TIMEOUT_SECONDS}} - Execution timeout
"""

import sys
import os
import json
import time
import traceback
import threading
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional

# ============== Configuration ==============

PROJECT_PATH = r'{{PROJECT_PATH}}'
FLOW_MODULE = '{{FLOW_MODULE}}'
FLOW_CLASS = '{{FLOW_CLASS}}'
FLOW_INPUTS = json.loads(r'''{{FLOW_INPUTS}}''')
HITL_RESPONSES = json.loads(r'''{{HITL_RESPONSES}}''')
EXPECTED_END_STEP = '{{EXPECTED_END_STEP}}'
TEST_ID = '{{TEST_ID}}'
PATH_ID = '{{PATH_ID}}'
ARTIFACT_DIR = '{{ARTIFACT_DIR}}'
TIMEOUT_SECONDS = {{TIMEOUT_SECONDS}}

# ============== Setup ==============

# Add project to path (including src/ for standard CrewAI project structure)
sys.path.insert(0, PROJECT_PATH)
src_path = os.path.join(PROJECT_PATH, 'src')
if os.path.exists(src_path):
    sys.path.insert(0, src_path)
# ============== Tracer Setup ==============
# Import shared tracer module (generated by Identro)
IDENTRO_DIR = os.path.join(PROJECT_PATH, '.identro')
sys.path.insert(0, IDENTRO_DIR)

try:
    from identro_tracer import (
        _identro_tracer,
        _patch_openai_sdk,
        _patch_crewai_llm,
        instrument_crewai,
        _in_flow_kickoff
    )
    TRACER_AVAILABLE = True
    
    # CRITICAL: Patch OpenAI SDK BEFORE importing CrewAI
    _patch_openai_sdk()
    
    # CRITICAL: Instrument CrewAI classes BEFORE loading flow module
    # This must happen before any crew files are imported, otherwise
    # Crew.kickoff, Agent.execute_task, etc. won't be patched
    instrument_crewai()
    _patch_crewai_llm()
except ImportError:
    TRACER_AVAILABLE = False
    _identro_tracer = None
    _in_flow_kickoff = None

# Set tracer context
if TRACER_AVAILABLE and _identro_tracer:
    _identro_tracer.set_context(
        test_id=TEST_ID,
        run_index=os.environ.get('IDENTRO_RUN_INDEX', '-1'),
        agent_name=FLOW_CLASS
    )

# Load environment
try:
    from dotenv import load_dotenv
    load_dotenv(os.path.join(PROJECT_PATH, '.env'))
except ImportError:
    pass

# Suppress warnings for cleaner output
import warnings
warnings.filterwarnings("ignore")

# ============== Execution State ==============

class FlowExecutionState:
    """Tracks flow execution for trace building"""
    
    def __init__(self):
        self.test_id = TEST_ID
        self.path_id = PATH_ID
        self.start_time: str = datetime.utcnow().isoformat() + 'Z'
        self.end_time: Optional[str] = None
        self.steps: List[Dict] = []
        self.current_state: Dict[str, Any] = {}
        self.hitl_responses_used: int = 0
        self.hitl_response_index: int = 0
        self.crew_invocations: int = 0
        self.routing_decisions: List[Dict] = []
        self.final_output: Any = None
        self.error: Optional[Dict] = None
        self.artifacts: List[str] = []
        
    def add_step(self, method: str, step_type: str = 'execution'):
        """Add a step to the trace"""
        step = {
            'method': method,
            'timestamp': datetime.utcnow().isoformat() + 'Z',
            'duration': 0,  # Will be updated when step completes
            'stateBefore': dict(self.current_state),
            'stateAfter': {},  # Will be updated after step
            'stepType': step_type
        }
        self.steps.append(step)
        return len(self.steps) - 1  # Return index for later update
    
    def complete_step(self, step_index: int, state_after: Dict = None):
        """Mark a step as complete with final state"""
        if 0 <= step_index < len(self.steps):
            step = self.steps[step_index]
            start = datetime.fromisoformat(step['timestamp'].replace('Z', ''))
            step['duration'] = int((datetime.utcnow() - start).total_seconds() * 1000)
            step['stateAfter'] = state_after or dict(self.current_state)
    
    def add_hitl_interaction(self, method: str, hitl_type: str, prompt: str, response: Any):
        """Record HITL interaction in the trace"""
        hitl_info = {
            'type': hitl_type,
            'prompt': prompt,
            'response': response,
            'isSynthetic': True,
            'syntheticSource': 'flow-test-generator'
        }
        # Find the corresponding step and add HITL info
        for step in reversed(self.steps):
            if step['method'] == method or step.get('stepType') == 'hitl':
                step['hitlInteraction'] = hitl_info
                break
    
    def add_routing_decision(self, router_method: str, condition: str, selected: str, available: List[str]):
        """Record routing decision"""
        routing = {
            'routerMethod': router_method,
            'condition': condition,
            'selectedPath': selected,
            'availablePaths': available
        }
        self.routing_decisions.append(routing)
        # Add to corresponding step
        for step in reversed(self.steps):
            if step['method'] == router_method:
                step['routingDecision'] = routing
                break
    
    def add_crew_execution(self, crew_name: str, inputs: Dict, output: Any, duration: int):
        """Record crew execution"""
        crew_info = {
            'crewName': crew_name,
            'inputs': inputs,
            'output': str(output)[:500],  # Truncate for storage
            'duration': duration
        }
        self.crew_invocations += 1
        # Add to corresponding step
        for step in reversed(self.steps):
            step['crewExecution'] = crew_info
            break
    
    def finalize(self, success: bool, output: Any = None, error: Optional[Dict] = None):
        """Finalize the execution state"""
        self.end_time = datetime.utcnow().isoformat() + 'Z'
        self.final_output = output
        if error:
            self.error = error
    
    def get_last_step_method(self) -> str:
        """Get the last executed step method"""
        if self.steps:
            return self.steps[-1]['method']
        return ''
    
    def to_trace(self) -> Dict:
        """Convert to FlowTrace format"""
        return {
            'flowId': FLOW_CLASS,
            'testId': self.test_id,
            'pathId': self.path_id,
            'startTime': self.start_time,
            'endTime': self.end_time,
            'steps': self.steps
        }
    
    def to_result(self, success: bool) -> Dict:
        """Convert to FlowTestResult format"""
        # Calculate metrics
        start = datetime.fromisoformat(self.start_time.replace('Z', ''))
        end = datetime.fromisoformat(self.end_time.replace('Z', '')) if self.end_time else datetime.utcnow()
        duration = int((end - start).total_seconds() * 1000)
        
        return {
            'testId': self.test_id,
            'pathId': self.path_id,
            'trace': self.to_trace(),
            'finalState': self.current_state,
            'endStep': self.get_last_step_method(),
            'artifacts': self.artifacts,
            'metrics': {
                'duration': duration,
                'crewInvocations': self.crew_invocations,
                'hitlInteractions': self.hitl_responses_used,
                'loopIterations': None  # Can be calculated if needed
            },
            'success': success,
            'error': self.error.get('message') if self.error else None
        }

# Global state
execution_state = FlowExecutionState()

# ============== HITL Interception ==============

def get_next_hitl_response(method: str, prompt: str) -> Any:
    """Get the next pre-loaded HITL response"""
    responses = HITL_RESPONSES
    
    # Find response for this method
    for resp in responses:
        if resp.get('step') == method:
            # Check iteration if applicable
            iteration = resp.get('iteration')
            if iteration is not None:
                # Only use if iteration matches
                if iteration == execution_state.hitl_response_index:
                    execution_state.hitl_response_index += 1
                    execution_state.hitl_responses_used += 1
                    return resp.get('response', {})
            else:
                # No iteration specified, use first match
                execution_state.hitl_responses_used += 1
                return resp.get('response', {})
    
    # Try to find any unused response
    if execution_state.hitl_response_index < len(responses):
        resp = responses[execution_state.hitl_response_index]
        execution_state.hitl_response_index += 1
        execution_state.hitl_responses_used += 1
        return resp.get('response', {})
    
    # Default fallback
    return {'action': 'approve', 'reason': 'Default synthetic response'}

# Override input() for HITL capture
_original_input = input

def synthetic_input(prompt: str = '') -> str:
    """Synthetic input() replacement that uses pre-loaded responses"""
    method = 'input'  # Try to detect from call stack
    
    # Try to get method name from call stack
    import inspect
    for frame_info in inspect.stack():
        if frame_info.function not in ('synthetic_input', 'input', '<module>'):
            method = frame_info.function
            break
    
    # Add step for HITL
    step_idx = execution_state.add_step(method, 'hitl')
    
    # Get synthetic response
    response = get_next_hitl_response(method, prompt)
    
    # Determine the actual value to return
    if isinstance(response, dict):
        # For selection/approval types, extract the relevant value
        if 'choice' in response:
            value = response['choice']
        elif 'value' in response:
            value = response['value']
        elif 'action' in response:
            value = response['action']
        else:
            value = str(response)
    else:
        value = str(response)
    
    # Record HITL interaction
    execution_state.add_hitl_interaction(method, 'input', prompt, response)
    execution_state.complete_step(step_idx, {'hitl_response': value})
    
    # Output for monitoring
    print(f"HITL_CAPTURED:{json.dumps({'method': method, 'prompt': prompt, 'response': value})}", flush=True)
    
    return str(value)

# Install synthetic input
import builtins
builtins.input = synthetic_input

# ============== Flow Execution ==============

def load_flow_module():
    """Load the flow module and return (module, kickoff_function, flow_class)"""
    try:
        # Try direct module import
        module = __import__(FLOW_MODULE, fromlist=[FLOW_CLASS, 'kickoff'])
        
        # First, check for a kickoff function (preferred for typed flows)
        kickoff_func = getattr(module, 'kickoff', None)
        
        # Also get the flow class if available
        flow_class = None
        if hasattr(module, FLOW_CLASS):
            flow_class = getattr(module, FLOW_CLASS)
        else:
            # Try as a class in a submodule
            for attr_name in dir(module):
                attr = getattr(module, attr_name)
                if hasattr(attr, '__name__') and attr.__name__ == FLOW_CLASS:
                    flow_class = attr
                    break
        
        return module, kickoff_func, flow_class
        
    except ImportError as e:
        # Try alternative import paths
        try:
            # Maybe it's main.py with a Flow class
            sys.path.insert(0, os.path.join(PROJECT_PATH, 'src'))
            module = __import__(f'{FLOW_MODULE.replace("/", ".")}.main', fromlist=[FLOW_CLASS, 'kickoff'])
            kickoff_func = getattr(module, 'kickoff', None)
            flow_class = getattr(module, FLOW_CLASS, None)
            return module, kickoff_func, flow_class
        except:
            raise ImportError(f"Could not import flow module '{FLOW_MODULE}': {e}")

def capture_artifacts():
    """Capture generated artifacts"""
    if not ARTIFACT_DIR or ARTIFACT_DIR == '{{ARTIFACT_DIR}}':
        return
    
    artifact_path = Path(ARTIFACT_DIR)
    if not artifact_path.exists():
        return
    
    for file_path in artifact_path.rglob('*'):
        if file_path.is_file():
            execution_state.artifacts.append(str(file_path))

def get_flow_state_class(flow_class):
    """
    Get the state class for a typed flow (Flow[StateClass]).
    Returns None if the flow doesn't have a typed state.
    """
    try:
        # Check if flow has initial_state attribute (the state class)
        if hasattr(flow_class, 'initial_state'):
            return flow_class.initial_state
        
        # Check type hints for generic state
        import typing
        if hasattr(flow_class, '__orig_bases__'):
            for base in flow_class.__orig_bases__:
                if hasattr(base, '__origin__') and hasattr(base, '__args__'):
                    args = typing.get_args(base)
                    if args and len(args) > 0:
                        state_class = args[0]
                        if isinstance(state_class, type):
                            return state_class
        return None
    except Exception:
        return None


def extract_full_flow_state(flow_instance, result) -> dict:
    """
    Extract the complete flow state from a flow instance after execution.
    Returns a structured dict with all state fields (no truncation).
    
    For CrewAI flows, the state accumulates outputs from all crews/steps.
    This is what the LLM evaluator needs to assess the flow's behavior.
    """
    state_dict = {
        '_isFlowState': True,  # Marker for evaluator to detect flow output
        '_flowClass': type(flow_instance).__name__ if flow_instance else 'unknown',
        '_executionResult': None,
        'fields': {}
    }
    
    try:
        # Priority 1: Get state from flow_instance.state (typed flows)
        if flow_instance and hasattr(flow_instance, 'state'):
            flow_state = flow_instance.state
            
            # Handle Pydantic models (most common for typed flows)
            if hasattr(flow_state, 'model_dump'):
                state_dict['fields'] = flow_state.model_dump()
            # Handle dataclasses
            elif hasattr(flow_state, '__dataclass_fields__'):
                from dataclasses import asdict
                state_dict['fields'] = asdict(flow_state)
            # Handle objects with __dict__
            elif hasattr(flow_state, '__dict__'):
                state_dict['fields'] = {
                    k: v for k, v in flow_state.__dict__.items() 
                    if not k.startswith('_')
                }
            # Fallback: dict-like state
            elif isinstance(flow_state, dict):
                state_dict['fields'] = flow_state
            else:
                # Last resort: convert to string
                state_dict['fields'] = {'raw_state': str(flow_state)}
        
        # Priority 2: Extract from result if it's a state object
        if result is not None:
            if hasattr(result, 'model_dump'):
                state_dict['_executionResult'] = result.model_dump()
            elif hasattr(result, '__dict__'):
                state_dict['_executionResult'] = {
                    k: v for k, v in result.__dict__.items()
                    if not k.startswith('_')
                }
            elif isinstance(result, dict):
                state_dict['_executionResult'] = result
            else:
                state_dict['_executionResult'] = str(result)
        
        # Priority 3: Check for tasks_output if available (crew outputs)
        if flow_instance and hasattr(flow_instance, 'tasks_output'):
            tasks_output = flow_instance.tasks_output
            if tasks_output:
                state_dict['_tasksOutput'] = [
                    str(t)[:5000] for t in tasks_output
                ]
        
    except Exception as e:
        state_dict['_extractionError'] = str(e)
    
    return state_dict


def unwrap_flow_inputs(raw_inputs: dict) -> dict:
    """
    Unwrap test inputs to get the actual flow inputs.
    
    Test inputs may come in various wrapper formats:
    1. {"flowInputs": "...", "hitlResponses": []} - wrapped string input
    2. {"flowInputs": {...}, "hitlResponses": []} - wrapped dict input
    3. {"parameters": {...}} - TestInput format
    4. Direct dict of state fields - no unwrapping needed
    
    Returns the actual inputs to pass to the flow.
    """
    if not raw_inputs or not isinstance(raw_inputs, dict):
        return {}
    
    # Priority 1: Extract "flowInputs" if present (wrapper format)
    if 'flowInputs' in raw_inputs:
        flow_inputs = raw_inputs['flowInputs']
        # If flowInputs is a string, return it as-is (will be handled by prepare_state_inputs)
        if isinstance(flow_inputs, str):
            return {'_rawInput': flow_inputs}
        # If flowInputs is a dict, return it directly
        elif isinstance(flow_inputs, dict):
            return flow_inputs
        else:
            return {'_rawInput': str(flow_inputs)}
    
    # Priority 2: Extract "parameters" if present (TestInput format)
    if 'parameters' in raw_inputs:
        params = raw_inputs['parameters']
        if isinstance(params, dict):
            return params
        else:
            return {'_rawInput': str(params)}
    
    # Priority 3: Filter out meta keys, return remaining as state fields
    meta_keys = {'hitlResponses', 'scenario', 'description'}
    filtered = {k: v for k, v in raw_inputs.items() if k not in meta_keys}
    return filtered


def prepare_state_inputs(inputs: dict, state_class) -> dict:
    """
    Prepare inputs for a typed flow state class.
    
    Handles the case where:
    1. inputs is already a proper state dict → return as-is
    2. inputs contains '_rawInput' string → try to match to state fields
    3. inputs is partial → fill in missing required fields with defaults
    
    This is generic - no hardcoded field names.
    """
    if not state_class:
        return inputs
    
    # Get expected field names from state class
    expected_fields = set()
    defaults = {}
    
    # Handle Pydantic models
    if hasattr(state_class, 'model_fields'):
        from pydantic_core import PydanticUndefined
        for field_name, field_info in state_class.model_fields.items():
            expected_fields.add(field_name)
            # Get default value if available (check for PydanticUndefined)
            if field_info.default is not PydanticUndefined:
                defaults[field_name] = field_info.default
            elif field_info.default_factory is not None:
                try:
                    defaults[field_name] = field_info.default_factory()
                except:
                    pass
    # Handle dataclasses
    elif hasattr(state_class, '__dataclass_fields__'):
        from dataclasses import fields, MISSING
        for f in fields(state_class):
            expected_fields.add(f.name)
            if f.default is not MISSING:
                defaults[f.name] = f.default
            elif f.default_factory is not MISSING:
                defaults[f.name] = f.default_factory()
    
    # If inputs already has expected fields, use them directly
    if expected_fields and any(k in expected_fields for k in inputs):
        # Return only the fields that the state class expects
        return {k: v for k, v in inputs.items() if k in expected_fields}
    
    # If we have a raw string input, we can't pass it directly to a complex state class
    # The flow will run with defaults - the raw input is really just test metadata
    if '_rawInput' in inputs:
        # Return empty dict - let the flow use its default state
        # The test scenario text is for the LLM evaluation, not flow initialization
        return {}
    
    return inputs


def run_flow():
    """Execute the flow and capture trace"""
    print(f"FLOW_TEST_START:{json.dumps({'testId': TEST_ID, 'pathId': PATH_ID, 'flowClass': FLOW_CLASS})}", flush=True)
    
    # Start root span for flow
    root_span = None
    flow_guard_token = None
    if TRACER_AVAILABLE and _identro_tracer:
        # Set re-entrancy guard to prevent nested flow_kickoff spans
        # This prevents the patched Flow.kickoff from creating duplicate spans
        if _in_flow_kickoff is not None:
            flow_guard_token = _in_flow_kickoff.set(True)
        
        # Start span with initial state (inputs) for state diff tracking
        root_span = _identro_tracer.start_span_with_state("flow_kickoff", {
            "flow_name": FLOW_CLASS,
            "test_id": TEST_ID,
            "path_id": PATH_ID
        }, state_before={"inputs": FLOW_INPUTS})
    
    try:
        # Load flow module (returns module, kickoff_func, flow_class)
        print("FLOW_LOADING", flush=True)
        module, kickoff_func, flow_class = load_flow_module()
        
        # CRITICAL: Now that CrewAI is imported (via the flow module), instrument it
        # This patches Crew.kickoff, Agent.execute_task, Task.execute, etc. for full tracing
        if TRACER_AVAILABLE:
            try:
                instrument_crewai()
                _patch_crewai_llm()
                print("TRACER_INSTRUMENTED:crewai", flush=True)
            except Exception as e:
                print(f"TRACER_INSTRUMENT_WARNING:{str(e)}", flush=True)
        
        # Prefer kickoff function if available (handles typed flows properly)
        if kickoff_func:
            print(f"FLOW_LOADED:{FLOW_CLASS} (using kickoff function)", flush=True)
        elif flow_class:
            print(f"FLOW_LOADED:{FLOW_CLASS} (using flow class)", flush=True)
        else:
            raise ImportError(f"Could not find kickoff function or flow class '{FLOW_CLASS}'")
        
        # Record start step
        execution_state.add_step('flow_start', 'init')
        execution_state.current_state = {'inputs': FLOW_INPUTS}
        
        # Execute flow
        print("FLOW_EXECUTING", flush=True)
        step_idx = execution_state.add_step('kickoff', 'execution')
        
        start_time = time.time()
        flow_instance = None  # Track flow instance for state extraction
        
        # Unwrap test inputs to get actual flow inputs (generic - works with any project)
        unwrapped_inputs = unwrap_flow_inputs(FLOW_INPUTS)
        print(f"FLOW_INPUTS_UNWRAPPED:{json.dumps(unwrapped_inputs)[:500]}", flush=True)
        
        # ALWAYS instantiate the flow class to access state after execution
        # Even if there's a kickoff function, we need the instance for state access
        if flow_class:
            print("FLOW_INSTANTIATING", flush=True)
            flow_instance = flow_class()
            execution_state.complete_step(0, {'flow_instance': type(flow_instance).__name__})
            
            # Check if this is a typed flow with state class
            state_class = get_flow_state_class(flow_class)
            
            # Prepare inputs for the specific state class (generic approach)
            prepared_inputs = prepare_state_inputs(unwrapped_inputs, state_class)
            print(f"FLOW_INPUTS_PREPARED:{json.dumps(prepared_inputs)[:500]}", flush=True)
            
            if state_class and prepared_inputs:
                # For typed flows (Flow[StateClass]), try multiple approaches
                print(f"FLOW_STATE_CLASS:{state_class.__name__}", flush=True)
                try:
                    # Approach 1: Set state directly (for flows with settable state)
                    flow_instance.state = state_class(**prepared_inputs)
                    result = flow_instance.kickoff()
                except (TypeError, AttributeError) as e:
                    # Approach 2: State not settable, try kickoff with inputs
                    print(f"FLOW_STATE_INIT_FALLBACK:{str(e)}", flush=True)
                    try:
                        result = flow_instance.kickoff(inputs=prepared_inputs)
                    except TypeError:
                        # Approach 3: kickoff doesn't accept inputs, just call it
                        result = flow_instance.kickoff()
            elif prepared_inputs:
                # For untyped flows, try kickoff with inputs
                try:
                    result = flow_instance.kickoff(inputs=prepared_inputs)
                except TypeError:
                    # kickoff doesn't accept inputs
                    result = flow_instance.kickoff()
            else:
                # No inputs provided
                result = flow_instance.kickoff()
        else:
            raise ImportError(f"No executable flow found for '{FLOW_CLASS}'")
        
        duration = int((time.time() - start_time) * 1000)
        
        # ===== CRITICAL: Extract FULL flow state for LLM evaluation =====
        # flow_instance is now always instantiated above (when flow_class exists)
        # Extract full state - this is what the LLM evaluator needs
        full_flow_state = extract_full_flow_state(flow_instance, result)
        
        # Store both truncated (for backward compat) and full state
        execution_state.current_state['result'] = str(result)[:1000]  # Legacy
        execution_state.current_state['flowState'] = full_flow_state  # NEW: Full state
        
        execution_state.complete_step(step_idx, execution_state.current_state)
        
        # Record completion
        execution_state.add_step(EXPECTED_END_STEP or 'flow_complete', 'complete')
        execution_state.complete_step(len(execution_state.steps) - 1)
        
        # Capture artifacts
        capture_artifacts()
        
        # Finalize
        execution_state.finalize(success=True, output=result)
        
        # Validate path
        end_step = execution_state.get_last_step_method()
        path_valid = end_step == EXPECTED_END_STEP if EXPECTED_END_STEP else True
        
        # Output result with FULL flow state for evaluation
        test_result = execution_state.to_result(success=True)
        test_result['pathValidation'] = {
            'expected': EXPECTED_END_STEP,
            'actual': end_step,
            'valid': path_valid
        }
        
        # ===== NEW: Include full flow state in rawOutput for LLM evaluation =====
        # This replaces the simple str(result) with structured state data
        test_result['rawOutput'] = json.dumps(full_flow_state)
        test_result['isFlowState'] = True  # Marker for evaluator
        
        print(f"FLOW_RESULT:{json.dumps(test_result)}", flush=True)
        print(f"FLOW_SUCCESS", flush=True)

        if TRACER_AVAILABLE and _identro_tracer:
            # End span with final state for diff tracking
            _identro_tracer.end_span_with_state(root_span, result=result, state_after=full_flow_state)
            _identro_tracer.flush()
        
        return test_result
        
    except Exception as e:
        error_info = {
            'type': type(e).__name__,
            'message': str(e),
            'stack': traceback.format_exc()
        }
        if TRACER_AVAILABLE and _identro_tracer:
            # End span with error state
            _identro_tracer.end_span_with_state(root_span, error=e, state_after={'error': str(e)})
            _identro_tracer.flush()

        
        execution_state.finalize(success=False, error=error_info)
        
        test_result = execution_state.to_result(success=False)
        test_result['error'] = error_info
        
        print(f"FLOW_ERROR:{json.dumps(error_info)}", flush=True)
        print(f"FLOW_RESULT:{json.dumps(test_result)}", flush=True)
        
        return test_result

# ============== Main ==============

def main():
    """Main entry point with timeout handling"""
    
    result = None
    error = None
    
    def run_with_result():
        nonlocal result, error
        try:
            result = run_flow()
        except Exception as e:
            error = str(e)
    
    # Run with timeout
    thread = threading.Thread(target=run_with_result)
    thread.daemon = True
    thread.start()
    thread.join(timeout=TIMEOUT_SECONDS)
    
    if thread.is_alive():
        # Timeout occurred
        error_info = {
            'type': 'TimeoutError',
            'message': f'Flow execution exceeded {TIMEOUT_SECONDS} seconds',
            'stack': ''
        }
        execution_state.finalize(success=False, error=error_info)
        test_result = execution_state.to_result(success=False)
        test_result['error'] = error_info
        print(f"FLOW_TIMEOUT:{json.dumps(error_info)}", flush=True)
        print(f"FLOW_RESULT:{json.dumps(test_result)}", flush=True)
    
    print("FLOW_SHUTDOWN", flush=True)

if __name__ == '__main__':
    main()
