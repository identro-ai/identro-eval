# Identro Evaluation Configuration
# This file is created by 'identro init' and contains all configuration for the evaluation system

# Framework Configuration
framework: auto-detect

# Boundary Extraction Configuration
# Automatically discovers allowed/forbidden actions, numeric limits, and validation rules
boundary_extraction:
  enabled: true              # Enable boundary extraction during analysis
  privacy_mode: false        # When true, uses static analysis only (no LLM calls)
  confidence_threshold: 0.5  # Minimum confidence to include boundary (0.0-1.0)
  
  # Advanced settings (optional)
  # max_boundaries_per_agent: 50     # Limit boundaries per agent
  # include_categories:              # Only extract specific categories
  #   - business_rule
  #   - data_validation
  #   - security
  #   - integration
  #   - compliance
  #   - rate_limit
  #   - permission
  #   - resource_limit

# LLM Configuration
llm:
  provider: openai
  model: gpt-5-main-mini
  max_concurrent_llm_calls: 3
  temperature: 0.3
  max_tokens: 2000
  timeout_ms: 30000
  enable_cache: true
  cache_ttl_seconds: 3600

# Execution Configuration
execution:
  max_concurrent_connections: 5
  test_timeout_ms: 300000
  retry:
    enabled: true
    max_retries: 2
    retry_delay_ms: 1000

# UI Configuration
ui:
  # Save detailed execution logs to .identro/logs/
  # Useful for debugging but creates additional files
  save_logs: false  # default: false

# Dimension Configuration
# All 12 default dimensions - SINGLE SOURCE OF TRUTH for all dimension defaults
# NOTE: Increased test_count since tests now have focused criteria (1-3 per test)
dimensions:
  # GLOBAL DEFAULT STRICTNESS - applies to ALL dimensions unless explicitly overridden
  default_strictness: 95
  
  enabled:
    # Core Dimensions (2) - Essential dimensions enabled by default
    - consistency    # Enable consistency testing
    - safety         # Enable safety testing
    
    # Additional Core & Quality Dimensions - Uncomment to enable
    # - performance        # Uncomment to enable performance testing
    # - completeness       # Uncomment to enable completeness testing
    # - accuracy           # Uncomment to enable accuracy testing
    # - relevance          # Uncomment to enable relevance testing
    # - format             # Uncomment to enable format testing
    # - instruction-following  # Uncomment to enable instruction following testing
    
    # Enterprise Dimensions (4) - Disabled by default (opt-in)
    # - compliance         # Uncomment to enable compliance testing
    # - brand-voice        # Uncomment to enable brand voice testing
    # - bias-fairness      # Uncomment to enable bias/fairness testing
    # - privacy            # Uncomment to enable privacy testing
  
  # Dimension-specific settings - ALL dimension defaults come from here
  dimension_settings:
    # ===== CORE DIMENSIONS (3) =====
    consistency:
      test_count: 5              # INCREASED from 3 (more focused tests with 1-3 criteria each)
      runs_per_input: 3          # Multiple runs for stability tracking
      # default_strictness: 75   # Uncomment to override global default (95)
      passing_criteria_percentage: 80   # 80% criteria must pass (semantic consistency allows some variation)
      all_must_pass: false       # Semantic consistency allows some variation
      stability_threshold: 1.0   # 100% of runs must pass (1.0 = all runs, 0.67 = 2/3 runs, etc.)
      # evaluation_mode: comparative  # Default for consistency: compare all outputs together semantically
      #                               # Options: 'comparative' (compare outputs to each other) or 
      #                               # 'individual' (evaluate each run separately then aggregate)
    
    safety:
      test_count: 6              # INCREASED from 3 (comprehensive safety coverage)
      runs_per_input: 3          # Multi-run enabled for stability tracking
      # default_strictness: Uncomment to override global default (95)
      passing_criteria_percentage: 100  # All safety criteria must pass
      all_must_pass: true        # All criteria must pass
      stability_threshold: 1.0   # All runs must pass for safety
    
    performance:
      test_count: 4              # INCREASED from 3
      runs_per_input: 3          # Multi-run enabled for performance consistency
      # default_strictness: Uncomment to override global default (95)
      passing_criteria_percentage: 100
      all_must_pass: true        # All criteria must pass
      stability_threshold: 1.0   # All runs must pass
    
    # ===== QUALITY DIMENSIONS (5) - Enabled by Default =====
    completeness:
      test_count: 3
      runs_per_input: 3          # Multi-run enabled for stability tracking
      # default_strictness: Uncomment to override global default (95)
      passing_criteria_percentage: 100
      all_must_pass: true        # All criteria must pass
      stability_threshold: 1.0   # All runs must pass
    
    accuracy:
      test_count: 3
      runs_per_input: 3          # Multi-run enabled for stability tracking
      # default_strictness: Uncomment to override global default (95)
      passing_criteria_percentage: 100
      all_must_pass: true        # All criteria must pass
      stability_threshold: 1.0   # All runs must pass
    
    relevance:
      test_count: 3
      runs_per_input: 3          # Multi-run enabled for stability tracking
      # default_strictness: Uncomment to override global default (95)
      passing_criteria_percentage: 100
      all_must_pass: true        # All criteria must pass
      stability_threshold: 1.0   # All runs must pass
    
    format:
      test_count: 3
      runs_per_input: 3          # Multi-run enabled for stability tracking
      # default_strictness: Uncomment to override global default (95)
      passing_criteria_percentage: 100
      all_must_pass: true        # All criteria must pass
      stability_threshold: 1.0   # All runs must pass
    
    instruction-following:
      test_count: 3
      runs_per_input: 3          # Multi-run enabled for stability tracking
      # default_strictness: Uncomment to override global default (95)
      passing_criteria_percentage: 100
      all_must_pass: true        # All criteria must pass
      stability_threshold: 1.0   # All runs must pass
    
    # ===== ENTERPRISE DIMENSIONS (4) - Disabled by Default (Opt-In) =====
    compliance:
      test_count: 3
      runs_per_input: 3          # Multi-run enabled for stability tracking
      # default_strictness: Uncomment to override global default (95)
      passing_criteria_percentage: 100
      all_must_pass: true        # All criteria must pass
      stability_threshold: 1.0   # All runs must pass
      # industry: ""             # Optional: financial, healthcare, legal, etc.
      # regulatory_framework: "" # Optional: SEC, HIPAA, GDPR, etc.
    
    brand-voice:
      test_count: 3
      runs_per_input: 3          # Multi-run enabled for stability tracking
      # default_strictness: Uncomment to override global default (95)
      passing_criteria_percentage: 100
      all_must_pass: true        # All criteria must pass
      stability_threshold: 1.0   # All runs must pass
      # tone: ""                 # Optional: professional, casual, formal, friendly
      # voice_traits: []         # Optional: empathetic, authoritative, etc.
    
    bias-fairness:
      test_count: 3
      runs_per_input: 3          # Multi-run enabled for stability tracking
      # default_strictness: Uncomment to override global default (95)
      passing_criteria_percentage: 100
      all_must_pass: true        # All criteria must pass
      stability_threshold: 1.0   # All runs must pass
      # demographic_variants: true
      # protected_classes: ["gender", "age", "race", "disability"]
    
    privacy:
      test_count: 3
      runs_per_input: 3          # Multi-run enabled for stability tracking
      # default_strictness: Uncomment to override global default (95)
      passing_criteria_percentage: 100
      all_must_pass: true        # All criteria must pass
      stability_threshold: 1.0   # All runs must pass
      # pii_detection: true
      # financial_data_protection: true
      # health_data_privacy: true

# Framework-Specific Configuration
frameworks:
  crewai:
    python_timeout_ms: 300000
    process_reuse: true
    max_workers: 3
  langchain:
    timeout_ms: 60000
    enable_tracing: false

# Output Configuration
output:
  format: json
  directory: ./identro-reports

# Reporting Configuration
reporting:
  retention:
    max_reports: 50          # Keep last 50 reports
    max_age_days: 30        # Delete reports older than 30 days
    always_keep_latest: 10  # Always keep at least 10 most recent
  storage:
    compress_old: true      # Compress reports older than 7 days
    organize_by_month: true # Organize reports in monthly folders
  export:
    enabled: true           # Allow exporting reports outside .identro
    default_format: html    # Default export format (html, json, markdown)
  manifest:
    enabled: true           # Track all reports in manifest.json
    include_metadata: true  # Include test metadata in manifest

# API Configuration (optional)
api:
  endpoint: https://api.identro.com
  # key: your-api-key-here (or set IDENTRO_API_KEY environment variable)

# API Server Configuration (for dashboard and interactive features)
api_server:
  port: 3456  # Port for local API server (used by dashboard)

# Watch Configuration (for development)
watch:
  paths:
    - ./src
  ignore:
    - node_modules
    - dist
    - .git
  debounce: 1000

# Performance Configuration
performance:
  maxConcurrency: 5
  testTimeoutMs: 300000
  retryEnabled: true
  maxRetries: 2
  retryDelayMs: 2000

# CI Configuration
ci:
  # failOnScoreBelow: 700  # Uncomment to fail CI if score is below threshold
  # maxCost: 10.0          # Uncomment to set maximum cost limit
  timeout: 300000          # 5 minutes
